1
00:00:00,000 --> 00:00:02,920
OK,

2
00:00:02,920 --> 00:00:06,640
so I want to talk
about diffusion models.

3
00:00:06,640 --> 00:00:09,040
So this is,

4
00:00:09,040 --> 00:00:15,040
I guess,
rounding out the generative image parts.

5
00:00:15,040 --> 00:00:17,760
I know there was,

6
00:00:17,760 --> 00:00:19,560
when I sent out
the survey at the beginning of the class,

7
00:00:19,560 --> 00:00:22,000
I know there was interest
on generative AI.

8
00:00:22,000 --> 00:00:22,520
Actually,

9
00:00:22,520 --> 00:00:25,400
I'm not sure if it was mainly just the LLM stuff,

10
00:00:25,400 --> 00:00:31,080
which we covered,
or also the vision stuff.

11
00:00:31,080 --> 00:00:33,880
But so for diffusion models,

12
00:00:33,880 --> 00:00:36,800
as I alluded
to last time,

13
00:00:36,800 --> 00:00:44,280
so you're not going
to get through all of the details of how diffusion models work.

14
00:00:44,280 --> 00:00:45,800
It's just very math - heavy,

15
00:00:45,800 --> 00:00:48,320
ideally.

16
00:00:48,320 --> 00:00:49,640
I mean,

17
00:00:49,640 --> 00:00:54,680
I can imagine
a short course just on generative image models.

18
00:00:54,680 --> 00:00:57,000
And diffusion models,

19
00:00:57,000 --> 00:00:59,200
there's so much going on.

20
00:00:59,200 --> 00:01:01,360
So what I hope to do last time

21
00:01:01,360 --> 00:01:08,880
is at least give you a sense,
build some intuition about what's going on.

22
00:01:08,880 --> 00:01:10,360
And you'll have to dive in.

23
00:01:10,360 --> 00:01:11,360
And actually,

24
00:01:11,360 --> 00:01:14,040
if anyone's interested,

25
00:01:14,040 --> 00:01:20,520
happy to do a little side project with you if you want.

26
00:01:20,520 --> 00:01:27,080
I can always create
more content as well.

27
00:01:27,080 --> 00:01:30,040
So also,
like last time,

28
00:01:30,040 --> 00:01:34,720
the book,
at least the way the book organized things,

29
00:01:34,720 --> 00:01:37,360
I didn't find it that accessible.

30
00:01:37,360 --> 00:01:44,640
And so I'm going to rely
heavily on a similar blog from last time.

31
00:01:44,640 --> 00:01:48,000
And I guess this might be publicly available.

32
00:01:48,000 --> 00:01:51,000
I realize I referenced towards data science

33
00:01:51,000 --> 00:01:52,120
because I subscribe.

34
00:01:52,120 --> 00:01:54,160
If you don't have access,

35
00:01:54,160 --> 00:01:57,320
and I'm pointing to something that you don't have access,

36
00:01:57,320 --> 00:01:59,160
just let me know.

37
00:01:59,160 --> 00:02:04,760
I can do like a print
screen or something of the site

38
00:02:04,760 --> 00:02:10,000
and share it.

39
00:02:10,000 --> 00:02:10,920
Oh,

40
00:02:10,920 --> 00:02:13,640
and then in terms of announcements,

41
00:02:13,640 --> 00:02:15,800
so did Xavier reach out to,

42
00:02:15,800 --> 00:02:17,360
last time I mentioned,

43
00:02:17,360 --> 00:02:18,520
you're nodding
your head,

44
00:02:18,520 --> 00:02:20,280
yeah,

45
00:02:20,280 --> 00:02:24,040
so what I asked him to do is take the five people
on the top of the leaderboard.

46
00:02:24,040 --> 00:02:26,520
So am I remembering
right?

47
00:02:26,520 --> 00:02:27,800
It's like Andy,

48
00:02:27,800 --> 00:02:28,320
Jessica,

49
00:02:28,320 --> 00:02:30,200
Fareed,
Jasmine,

50
00:02:30,200 --> 00:02:31,920
who else?

51
00:02:31,920 --> 00:02:33,520
And you're as well.

52
00:02:33,520 --> 00:02:34,800
Yeah,

53
00:02:34,800 --> 00:02:36,800
and so what I asked

54
00:02:36,800 --> 00:02:39,320
Xavier is just organize,

55
00:02:39,320 --> 00:02:44,080
just collect amongst you just what your training tactic was

56
00:02:44,080 --> 00:02:45,880
and what model you use.

57
00:02:45,880 --> 00:02:47,560
And then he'll put it together in a slide

58
00:02:47,560 --> 00:02:50,720
if there's not a huge difference.

59
00:02:50,720 --> 00:02:54,160
But let's spend
at least a few minutes,

60
00:02:54,160 --> 00:02:59,120
10 minutes,
or something at the beginning of next class on Tuesday.

61
00:02:59,120 --> 00:03:00,320
That would be interesting.

62
00:03:00,320 --> 00:03:04,320
We can learn something
about your approaches.

63
00:03:04,320 --> 00:03:13,160
And congrats
for being top of the leaderboard too.

64
00:03:13,160 --> 00:03:15,880
And I think that's it for announcements.

65
00:03:15,880 --> 00:03:17,000
OK,

66
00:03:17,000 --> 00:03:23,560
so I'm going to try to give some context about how diffusion models
work

67
00:03:23,560 --> 00:03:24,880
and then go into a little bit of the theory.

68
00:03:24,880 --> 00:03:27,600
But I'm not going
to go into all of the math.

69
00:03:27,600 --> 00:03:31,240
It's just not conducive to try to do it

70
00:03:31,240 --> 00:03:34,160
in a lecture
format.

71
00:03:34,160 --> 00:03:35,080
And I forget who said it,

72
00:03:35,080 --> 00:03:39,200
but math is not a spectator
sport.

73
00:03:39,200 --> 00:03:45,000
And so I encourage you to go in and actually just kind of re - derive
either what's in the book

74
00:03:45,000 --> 00:03:47,120
or in this blog post here.

75
00:03:47,120 --> 00:03:49,000
Because even here,

76
00:03:49,000 --> 00:03:50,360
they skip some steps

77
00:03:50,360 --> 00:03:53,640
and I'll certainly skip some steps here.

78
00:03:53,640 --> 00:03:57,880
And then I'll talk
a little bit about how you get to training

79
00:03:57,880 --> 00:04:01,560
and then flash some application examples.

80
00:04:01,560 --> 00:04:08,680
OK,
so kind of like last time,

81
00:04:08,680 --> 00:04:14,680
the idea is that we're going to somehow figure out a probability
distribution.

82
00:04:14,680 --> 00:04:20,160
And we're going to try to generate new samples
from that probability distribution

83
00:04:20,160 --> 00:04:26,000
and the new samples will be hopefully high quality images.

84
00:04:26,000 --> 00:04:31,280
So the way diffusion models
work

85
00:04:31,280 --> 00:04:37,800
is that they essentially start kind of like with the variation

86
00:04:37,800 --> 00:04:40,680
al auto encoders and also GANs.

87
00:04:40,680 --> 00:04:43,440
And I'll make the comparison
here in a little bit.

88
00:04:43,440 --> 00:04:46,520
But like in the Wendy example,
it starts with just random noise.

89
00:04:46,520 --> 00:04:56,080
And basically what you've done is you learned
a generative model that can go from a purely Gaussian random distribution

90
00:04:56,080 --> 00:05:02,320
to some more complicated distribution that reflects the data set of images in this case.

91
00:05:02,320 --> 00:05:09,320
So it's the exact same thing
for images.

92
00:05:09,320 --> 00:05:11,840
It's just that it's a much higher dimensional space.

93
00:05:11,840 --> 00:05:19,160
But basically every color of every pixel,
you have a multidimensional distribution across that.

94
00:05:19,160 --> 00:05:22,400
So we're going to try,

95
00:05:22,400 --> 00:05:23,800
and just probably like last time,

96
00:05:23,800 --> 00:05:25,280
it seems counterintuitive,

97
00:05:25,280 --> 00:05:33,080
we're going to start from noise and somehow we're going to generate
these high quality images.

98
00:05:33,080 --> 00:05:36,640
So what's interesting,

99
00:05:36,640 --> 00:05:40,440
so I lectured in the slightly reversed order.

100
00:05:40,440 --> 00:05:46,040
But these three key papers
came out for each of these three areas just a year apart.

101
00:05:46,040 --> 00:05:49,440
So in 2013,

102
00:05:49,440 --> 00:05:53,240
King Ma and Welling introduced the variation<eol>al auto encoder,

103
00:05:53,240 --> 00:05:53,880
which I talked about.

104
00:05:53,880 --> 00:05:56,160
2014,

105
00:05:56,160 --> 00:05:59,120
Goodfellow and others introduced GANs.

106
00:05:59,120 --> 00:06:02,800
And then 2015,

107
00:06:02,800 --> 00:06:06,200
Saul Dijkstein introduced this paper.

108
00:06:06,200 --> 00:06:06,800
It's called

109
00:06:06,800 --> 00:06:11,920
Deep Unsupervised Learning Using Non - Equilibrium Thermodynamics.

110
00:06:11,920 --> 00:06:18,560
So it wasn't clear
from the paper title

111
00:06:18,560 --> 00:06:19,720
that these became the diffusion models.

112
00:06:19,720 --> 00:06:22,560
And there have been variations
of that since then.

113
00:06:22,560 --> 00:06:23,440
And of course,

114
00:06:23,440 --> 00:06:27,560
there's a lot of commercial,
so a lot of excitement,

115
00:06:27,560 --> 00:06:31,960
especially after these more efficient versions,
like stable diffusion,

116
00:06:31,960 --> 00:06:34,160
which I'm not going to really go into.

117
00:06:34,160 --> 00:06:37,880
I'll mention
very briefly at the end.

118
00:06:37,880 --> 00:06:39,600
But of course,

119
00:06:39,600 --> 00:06:40,440
Dali 2,

120
00:06:40,440 --> 00:06:42,600
Dali 3,

121
00:06:42,600 --> 00:06:44,480
Imogen from Google,

122
00:06:44,480 --> 00:06:46,800
Make a Scene from Meta,

123
00:06:46,800 --> 00:06:47,840
Imagine Video,

124
00:06:47,840 --> 00:06:50,200
so going into video space from Google

125
00:06:50,200 --> 00:06:52,960
and Make a Video from Meta,

126
00:06:52,960 --> 00:06:57,160
Stable Diffusion 3,
just came out from Stability AI.

127
00:06:57,160 --> 00:07:01,000
And then there's Mid Journey that they're on.

128
00:07:01,000 --> 00:07:04,680
Now they're model version 6.

129
00:07:04,680 --> 00:07:08,400
And you've seen examples.

130
00:07:08,400 --> 00:07:10,320
I'll show some today as well.

131
00:07:10,320 --> 00:07:12,360
But this is from Meta's Make a Scene

132
00:07:12,360 --> 00:07:18,960
that's generating
images from a sketch and a text prompt.

133
00:07:18,960 --> 00:07:23,440
They don't show the input here.

134
00:07:23,440 --> 00:07:27,760
But the idea is that you have a lot of creative control now.

135
00:07:27,760 --> 00:07:36,240
You can sketch and not just verbally describe what's going on.

136
00:07:36,240 --> 00:07:37,080
OK,

137
00:07:37,080 --> 00:07:42,000
so what's the basic idea
of these diffusion models?

138
00:07:42,000 --> 00:07:43,360
Or they call

139
00:07:43,360 --> 00:07:46,440
them
diffusion probabilistic models.

140
00:07:46,440 --> 00:07:51,320
So the idea is you take this,

141
00:07:51,320 --> 00:07:54,000
and I'll describe what this stochastic process is,

142
00:07:54,000 --> 00:07:57,080
but there's a forward process
that you take in your training.

143
00:07:57,080 --> 00:07:59,840
You take
all of these high quality images.

144
00:07:59,840 --> 00:08:01,640
And you slowly add noise to them,

145
00:08:01,640 --> 00:08:07,040
where you get to essentially a fully random image.

146
00:08:07,040 --> 00:08:11,680
But you have all of these samples.

147
00:08:11,680 --> 00:08:17,920
And then the goal of diffusion models is you're trying
to learn the reverse process.

148
00:08:17,920 --> 00:08:23,080
You're basically trying to figure out,
from a random sample,

149
00:08:23,080 --> 00:08:33,040
can I get back to one step at a time,
can I get back to some high quality image?

150
00:08:33,040 --> 00:08:36,400
And if there's no other information,

151
00:08:36,400 --> 00:08:39,880
it'll just come back to something
that's high quality.

152
00:08:39,880 --> 00:08:43,280
But there's these conditional diffusion models,

153
00:08:43,280 --> 00:08:46,440
just like the conditional GANs and VAEs,

154
00:08:46,440 --> 00:08:47,720
that you can give it

155
00:08:47,720 --> 00:08:50,160
text prompts,
or as we saw in the other one,

156
00:08:50,160 --> 00:08:53,360
give it even image
input

157
00:08:53,360 --> 00:08:57,160
to kind of guide how it does this reverse diffusion process.

158
00:08:57,160 --> 00:09:02,640
And OK,

159
00:09:02,640 --> 00:09:08,040
so we're going to hopefully give you some intuition about how this works.

160
00:09:08,040 --> 00:09:09,640
And so I'll start by,

161
00:09:09,640 --> 00:09:14,640
I'll talk
about what are stochastic processes,

162
00:09:14,640 --> 00:09:17,760
and specifically
diffusion processes,

163
00:09:17,760 --> 00:09:20,360
then give a little bit
of intuition,

164
00:09:20,360 --> 00:09:24,720
hopefully,
behind these diffusion probabilistic models.

165
00:09:24,720 --> 00:09:26,120
I'm going
to go into a little bit of math.

166
00:09:26,120 --> 00:09:27,760
Not going
to do the complete derivation,

167
00:09:27,760 --> 00:09:28,480
like I said,

168
00:09:28,480 --> 00:09:32,760
and then talk about how it's trained in practice.

169
00:09:32,760 --> 00:09:33,920
All right?

170
00:09:33,920 --> 00:09:35,880
OK,

171
00:09:35,880 --> 00:09:41,080
so let's just to kind of set things
up a little bit.

172
00:09:41,080 --> 00:09:44,040
When we're talking
about stochastic processes or diffusion processes,

173
00:09:44,040 --> 00:09:47,440
we're talking
about random variables.

174
00:09:47,440 --> 00:09:52,600
And what makes a random variable a stochastic process

175
00:09:52,600 --> 00:10:00,720
is that you basically have continuously varying
random variable in the continuous case,

176
00:10:00,720 --> 00:10:12,040
index by time,
or you can have discrete random variables that are just indexed either by indexing points of times

177
00:10:12,040 --> 00:10:18,360
or just simple indexing.

178
00:10:18,360 --> 00:10:21,560
And so when you have a random variable

179
00:10:21,560 --> 00:10:24,320
and you have a realization
of it,

180
00:10:24,320 --> 00:10:26,720
that's what we call it,
a sample.

181
00:10:26,720 --> 00:10:30,840
You have one example
or one sample from the random variable.

182
00:10:30,840 --> 00:10:33,520
But for the stochastic process,

183
00:10:33,520 --> 00:10:37,960
a realization
is a sample path.

184
00:10:37,960 --> 00:10:43,960
So over time,
how did that random variable kind of evolve over time?

185
00:10:43,960 --> 00:10:46,120
Let me show you some pictures.

186
00:10:46,120 --> 00:10:50,880
So there are,

187
00:10:50,880 --> 00:10:54,360
like I said,
there are discrete time and continuous time

188
00:10:54,360 --> 00:10:57,320
random variables.

189
00:10:57,320 --> 00:11:00,960
But there's also discrete value
and continuous value.

190
00:11:00,960 --> 00:11:03,320
So discrete time,

191
00:11:03,320 --> 00:11:06,720
let's say you're taking
daily average temperature.

192
00:11:06,720 --> 00:11:07,880
Once a day,

193
00:11:07,880 --> 00:11:11,360
you're recording
an average temperature

194
00:11:11,360 --> 00:11:13,840
or coin flipping discrete events.

195
00:11:13,840 --> 00:11:17,680
Whereas continuous time,

196
00:11:17,680 --> 00:11:18,800
you're monitoring
the,

197
00:11:18,800 --> 00:11:24,560
I guess,
the second - by - second stock price values.

198
00:11:24,560 --> 00:11:28,280
Or you're monitoring
queue length,

199
00:11:28,280 --> 00:11:30,840
which can change instantaneous<eol>ly.

200
00:11:30,840 --> 00:11:31,920
But presumably,

201
00:11:31,920 --> 00:11:33,560
it's like queue of people.

202
00:11:33,560 --> 00:11:37,880
It changes
by discrete value.

203
00:11:37,880 --> 00:11:46,160
So the temperatures are,
to some precision,

204
00:11:46,160 --> 00:11:48,000
are basically continuous value.

205
00:11:48,000 --> 00:11:51,120
It's the same to stock price.

206
00:11:51,120 --> 00:11:54,000
But coin flip,

207
00:11:54,000 --> 00:11:56,280
of course,
is discrete value.

208
00:11:56,280 --> 00:11:57,000
And queue length,

209
00:11:57,000 --> 00:11:58,720
if you're counting the number
of people

210
00:11:58,720 --> 00:12:00,280
or the number of jobs in your

211
00:12:00,280 --> 00:12:02,160
batch queue on the

212
00:12:02,160 --> 00:12:03,640
SCC,

213
00:12:03,640 --> 00:12:07,000
then they're going
to be discrete values.

214
00:12:07,000 --> 00:12:10,840
But the queue size can change,

215
00:12:10,840 --> 00:12:14,000
basically,

216
00:12:14,000 --> 00:12:21,360
instantaneous<eol>ly at any point in time.

217
00:12:21,360 --> 00:12:27,040
So we're going to use the properties
of a Markov process.

218
00:12:27,040 --> 00:12:28,840
And a Markov process is basically,

219
00:12:28,840 --> 00:12:31,840
it's a stochastic process,

220
00:12:31,840 --> 00:12:34,080
but as it says with no memory.

221
00:12:34,080 --> 00:12:43,400
So that just means that the current value at the current time is only dependent
on the previous value.

222
00:12:43,400 --> 00:12:46,640
So if it wasn't Markov process,

223
00:12:46,640 --> 00:12:50,520
then it can be dependent
on all the previous values

224
00:12:50,520 --> 00:12:56,000
or realizations of the process.

225
00:12:56,000 --> 00:12:58,480
But with Markov,

226
00:12:58,480 --> 00:12:59,960
basically,

227
00:12:59,960 --> 00:13:05,440
everything you need to know to figure out what's coming
next is in the last sample.

228
00:13:05,440 --> 00:13:11,640
OK,

229
00:13:11,640 --> 00:13:15,040
and so a diffusion process now is,

230
00:13:15,040 --> 00:13:22,160
so it can be described
by a stochastic differential equation.

231
00:13:22,160 --> 00:13:31,760
So differential equation is just something that's referring
like some infinitesimal change of some value,

232
00:13:31,760 --> 00:13:33,000
usually versus some other

233
00:13:33,000 --> 00:13:37,560
variable,
like time.

234
00:13:37,560 --> 00:13:44,560
But a stochastic differential process
has a random process inserted as well.

235
00:13:44,560 --> 00:13:48,600
And so this is kind
of the standard form,

236
00:13:48,600 --> 00:13:53,080
is here's our variable that we're trying
to predict

237
00:13:53,080 --> 00:13:55,120
or measure.

238
00:13:55,120 --> 00:13:56,680
You have this thing called

239
00:13:56,680 --> 00:13:59,280
the drift coefficient,
which is deterministic,

240
00:13:59,280 --> 00:14:03,000
but it can be dependent
on the value of your random variable

241
00:14:03,000 --> 00:14:04,440
and the point in time.

242
00:14:04,440 --> 00:14:08,360
So it can be varying
in a deterministic way.

243
00:14:08,360 --> 00:14:11,840
And then you have something
called a diffusion coefficient

244
00:14:11,840 --> 00:14:12,200
,

245
00:14:12,200 --> 00:14:17,280
which can be dependent
on the value of the random variable

246
00:14:17,280 --> 00:14:18,120
and the time.

247
00:14:18,120 --> 00:14:21,000
And then it's the

248
00:14:21,000 --> 00:14:26,000
product
with a so - called Wiener process

249
00:14:26,000 --> 00:14:29,120
that I'll describe here in a minute.

250
00:14:29,120 --> 00:14:31,720
And I'll show some pictures.

251
00:14:31,720 --> 00:14:33,440
And again,

252
00:14:33,440 --> 00:14:39,000
just to emphasize,
so the drift coefficient

253
00:14:39,000 --> 00:14:45,320
and the diffusion coefficient are functions
of the value of the random variable

254
00:14:45,320 --> 00:14:49,160
and time.

255
00:14:49,160 --> 00:14:49,920
OK,

256
00:14:49,920 --> 00:14:52,560
so as I said,

257
00:14:52,560 --> 00:14:55,040
this part here,

258
00:14:55,040 --> 00:14:58,360
if you just mask out this,
this is just a regular differential equation,

259
00:14:58,360 --> 00:15:00,040
but this makes it

260
00:15:00,040 --> 00:15:03,600
a stochastic differential equation.

261
00:15:03,600 --> 00:15:07,280
OK,

262
00:15:07,280 --> 00:15:12,840
so let's talk
about what a Wiener process is.

263
00:15:12,840 --> 00:15:19,720
So it's a continuous time
stochastic process that has these properties.

264
00:15:19,720 --> 00:15:22,360
Generally,
just by convention,

265
00:15:22,360 --> 00:15:26,920
the first sample is 0,

266
00:15:26,920 --> 00:15:32,360
kind of doesn't really matter where it starts.

267
00:15:32,360 --> 00:15:35,040
But it has independent
increments.

268
00:15:35,040 --> 00:15:37,000
And so it has this

269
00:15:37,000 --> 00:15:48,800
Markov property
that any two samples that are side by side

270
00:15:48,800 --> 00:15:52,840
are independent of all the past samples.

271
00:15:52,840 --> 00:15:57,560
And then probably the key thing
to take away here is that the difference,

272
00:15:57,560 --> 00:16:02,120
and so if I take,
even in the continuous case,

273
00:16:02,120 --> 00:16:08,080
if I take two samples
and I take the difference,

274
00:16:08,080 --> 00:16:14,280
they're going to be normally distributed with mean of 0.

275
00:16:14,280 --> 00:16:18,480
So I have
this Wiener process or Brownian motion process.

276
00:16:18,480 --> 00:16:21,240
I take a sample.

277
00:16:21,240 --> 00:16:23,400
Doesn't matter even when.

278
00:16:23,400 --> 00:16:25,640
I take another sample,

279
00:16:25,640 --> 00:16:30,000
some later point.

280
00:16:30,000 --> 00:16:34,520
That difference is going to be followed this

281
00:16:34,520 --> 00:16:38,920
Gaussian distribution with 0 mean.

282
00:16:38,920 --> 00:16:40,760
And the

283
00:16:40,760 --> 00:16:47,520
variance
is just related to the distance between the samples.

284
00:16:47,520 --> 00:16:48,160
I mean,

285
00:16:48,160 --> 00:16:48,760
think about it.

286
00:16:48,760 --> 00:16:53,160
So here's a picture
right here.

287
00:16:53,160 --> 00:16:59,560
These are just different
Wiener processes that start 0.

288
00:16:59,560 --> 00:17:01,800
And because of the random nature,

289
00:17:01,800 --> 00:17:03,200
of course,

290
00:17:03,200 --> 00:17:06,240
they'll have different paths.

291
00:17:06,240 --> 00:17:16,320
And so you can calculate
the standard deviation,

292
00:17:16,320 --> 00:17:24,120
which is just related
to the distance from the first sample,

293
00:17:24,120 --> 00:17:26,240
which is the gray area here.

294
00:17:26,240 --> 00:17:28,520
And so it kind of makes sense.

295
00:17:28,520 --> 00:17:30,760
If it's randomly
jumping up and down

296
00:17:30,760 --> 00:17:31,720
in this 1D case,

297
00:17:31,720 --> 00:17:37,440
the further away you get,
the more likely you are to be farther from 0.

298
00:17:37,440 --> 00:17:40,200
So it kind of makes sense.

299
00:17:40,200 --> 00:17:41,440
Yep?

300
00:17:41,440 --> 00:18:02,720
Is the curve
generated differentiable everywhere?

301
00:18:02,720 --> 00:18:05,360
Or is it not differentiable
anywhere?

302
00:18:05,360 --> 00:18:09,400
It's kind of jagged?

303
00:18:09,400 --> 00:18:10,080
Yeah.

304
00:18:10,080 --> 00:18:11,960
We are going
to be differentiating.

305
00:18:11,960 --> 00:18:13,400
But we're going
to be differentiating the equations,

306
00:18:13,400 --> 00:18:16,280
I guess,
for the curve.

307
00:18:16,280 --> 00:18:17,800
But I think what you're asking is,

308
00:18:17,800 --> 00:18:20,800
can you differentiate
the kind of the realizations?

309
00:18:20,800 --> 00:18:22,360
I mean,

310
00:18:22,360 --> 00:18:27,120
because you're referring
to the jagged nature.

311
00:18:27,120 --> 00:18:32,720
So I guess short answer is yes,
from an analytical perspective.

312
00:18:32,720 --> 00:18:39,360
So you'll see we'll have an expression
for this stochastic differential equation.

313
00:18:39,360 --> 00:18:42,520
And we will be differentiating,

314
00:18:42,520 --> 00:18:47,600
because we're going
to build that into our loss function of a network that we're going to be training.

315
00:18:47,600 --> 00:18:49,160
Makes sense?

316
00:18:49,160 --> 00:18:53,000
OK.

317
00:18:53,000 --> 00:18:57,160
So I do like my profiles.

318
00:18:57,160 --> 00:18:58,680
So I threw one in here.

319
00:18:58,680 --> 00:19:03,160
So the
Wiener process is named after Norbert Wiener.

320
00:19:03,160 --> 00:19:05,480
He's an interesting
character.

321
00:19:05,480 --> 00:19:06,920
He was at MIT.

322
00:19:06,920 --> 00:19:08,440
He's kind
of a child prodigy.

323
00:19:08,440 --> 00:19:11,920
But he was a computer scientist,

324
00:19:11,920 --> 00:19:12,800
and he died in

325
00:19:12,800 --> 00:19:16,640
64,
but in the early days.

326
00:19:16,640 --> 00:19:19,360
But he was credited with creating,

327
00:19:19,360 --> 00:19:23,880
at the time,
it was called the field of cybernetics.

328
00:19:23,880 --> 00:19:31,640
So he did a lot
of research around these kind of stochastic processes and these noise processes.

329
00:19:31,640 --> 00:19:34,000
And basically,

330
00:19:34,000 --> 00:19:39,400
they became key contributions
to areas in electrical engineering,

331
00:19:39,400 --> 00:19:42,480
communication,
control systems, like Wiener filter,

332
00:19:42,480 --> 00:19:45,560
if you've ever looked at control.

333
00:19:45,560 --> 00:19:47,480
And actually,

334
00:19:47,480 --> 00:19:51,440
we use it sometimes in computer vision.

335
00:19:51,440 --> 00:19:57,400
And so he was kind
of a contemporary or slightly older,

336
00:19:57,400 --> 00:19:58,480
but he influenced,

337
00:19:58,480 --> 00:19:59,120
like,

338
00:19:59,120 --> 00:20:01,720
John von Neumann,
who,

339
00:20:01,720 --> 00:20:02,400
you know,

340
00:20:02,400 --> 00:20:11,960
famous mathematician and was credited
with kind of inventing the modern computer architecture, the CPU

341
00:20:11,960 --> 00:20:13,160
kind of architecture.

342
00:20:13,160 --> 00:20:18,000
It's still called the von Neumann architecture
today. Claude

343
00:20:18,000 --> 00:20:20,320
Shannon,

344
00:20:20,320 --> 00:20:25,720
who's the basically creator of information
theory or information science.

345
00:20:25,720 --> 00:20:26,400
And so he,

346
00:20:26,400 --> 00:20:28,080
you know,
interesting enough,

347
00:20:28,080 --> 00:20:28,960
he wrote a,

348
00:20:28,960 --> 00:20:30,520
I put a link here,

349
00:20:30,520 --> 00:20:32,160
he wrote a paper in 1949

350
00:20:32,160 --> 00:20:33,520
called The Machine Age,

351
00:20:33,520 --> 00:20:34,280
you know,

352
00:20:34,280 --> 00:20:34,480
again,

353
00:20:34,480 --> 00:20:37,720
think back to 1949,
but anticipating,

354
00:20:37,720 --> 00:20:38,160
you know,

355
00:20:38,160 --> 00:20:40,760
a lot of what's happening
today

356
00:20:40,760 --> 00:20:45,880
around robots and things like that.

357
00:20:45,880 --> 00:20:46,520
And there was a,

358
00:20:46,520 --> 00:20:48,080
I don't know,

359
00:20:48,080 --> 00:20:49,160
if you're interested,

360
00:20:49,160 --> 00:20:49,760
there's an interesting book,

361
00:20:49,760 --> 00:20:51,240
I guess it's kind
of niche,

362
00:20:51,240 --> 00:20:53,400
but where they call him

363
00:20:53,400 --> 00:20:55,320
the Dark Hero of the Information Age,

364
00:20:55,320 --> 00:20:58,440
I found it interesting.

365
00:20:58,440 --> 00:21:03,800
And then the other little tidbit is that he's my great,
great grand advisor.

366
00:21:03,800 --> 00:21:05,760
So if you do
your academic genealogy,

367
00:21:05,760 --> 00:21:07,560
I'm one of the PhD students,

368
00:21:07,560 --> 00:21:10,080
probably know what I'm talking
about,

369
00:21:10,080 --> 00:21:14,560
that,
so my advisor was at MIT.

370
00:21:14,560 --> 00:21:21,320
His advisor,
Oppenheim and Schaefer, they kind of founded the field of digital signal processing,

371
00:21:21,320 --> 00:21:22,320
which I did my PhD in.

372
00:21:22,320 --> 00:21:24,200
And actually,

373
00:21:24,200 --> 00:21:26,480
interesting enough,
their advisor was Amar Bose

374
00:21:26,480 --> 00:21:28,680
, founder of Bose Corporation,

375
00:21:28,680 --> 00:21:31,280
and Bose was a student
of Norbert Wiener.

376
00:21:31,280 --> 00:21:36,720
So a little bit
of trivia.

377
00:21:36,720 --> 00:21:41,080
So I feel compelled to understand what he's done.

378
00:21:41,080 --> 00:21:42,720
I'm not sure I'm doing it justice,

379
00:21:42,720 --> 00:21:44,560
but.

380
00:21:44,560 --> 00:21:46,440
Okay,

381
00:21:46,440 --> 00:21:49,160
so let's go back.

382
00:21:49,160 --> 00:21:51,880
So we have these,

383
00:21:51,880 --> 00:21:53,160
just look at

384
00:21:53,160 --> 00:21:56,000
the,
think about the Wiener process itself.

385
00:21:56,000 --> 00:22:08,520
We can take those samples,
like a sample that's just some small time apart from another sample.

386
00:22:08,520 --> 00:22:14,480
And as I showed you on the other,
on the previous slide,

387
00:22:14,480 --> 00:22:20,080
that that difference is always going to be a zero mean,
and the standard deviation is always going to be the,

388
00:22:20,080 --> 00:22:24,480
basically,
the distance between the samples.

389
00:22:24,480 --> 00:22:27,440
So if you take samples
further apart,

390
00:22:27,440 --> 00:22:31,760
it's going
to have bigger standard deviation.

391
00:22:31,760 --> 00:22:35,680
That makes sense.

392
00:22:35,680 --> 00:22:38,080
Okay,

393
00:22:38,080 --> 00:22:50,360
so we can discretize
that stochastic differential equation by just taking two samples and subtracting them from each other.

394
00:22:50,360 --> 00:22:53,800
And that basically,

395
00:22:53,800 --> 00:22:59,560
so there's a little bit
of assumptions here,

396
00:22:59,560 --> 00:23:01,600
which I didn't make explicit.

397
00:23:01,600 --> 00:23:05,520
But I think they're assuming
that these are kind of slow moving.

398
00:23:05,520 --> 00:23:07,600
So these are,
this is an approximation.

399
00:23:07,600 --> 00:23:09,320
These are slow moving curves.

400
00:23:09,320 --> 00:23:14,200
And so they're not taking account that these values might have,

401
00:23:14,200 --> 00:23:17,000
might have changed.

402
00:23:17,000 --> 00:23:22,080
But it's just factoring in the difference
of the Wiener process here.

403
00:23:22,080 --> 00:23:25,560
And so it went from this,
the Wiener process

404
00:23:25,560 --> 00:23:27,080
to this,

405
00:23:27,080 --> 00:23:31,240
this zero mean Gaussian.

406
00:23:31,240 --> 00:23:33,240
Okay,

407
00:23:33,240 --> 00:23:37,400
by taking

408
00:23:37,400 --> 00:23:39,320
the,
taking the difference.

409
00:23:39,320 --> 00:23:43,760
And then we can just bring this term over here.

410
00:23:43,760 --> 00:23:45,600
And then if you have,

411
00:23:45,600 --> 00:23:51,000
so if you have a zero mean Gaussian and you're multiplying
it by some value,

412
00:23:51,000 --> 00:23:52,400
you're just changing,

413
00:23:52,400 --> 00:23:54,000
you're just creating
a new Gaussian.

414
00:23:54,000 --> 00:23:54,400
Right,

415
00:23:54,400 --> 00:23:57,160
and so u becomes u,
u prime.

416
00:23:57,160 --> 00:23:58,640
We're,

417
00:23:58,640 --> 00:24:01,560
we're multiplying
it by something.

418
00:24:01,560 --> 00:24:04,280
So this is now just a Gaussian,

419
00:24:04,280 --> 00:24:06,880
zero mean.

420
00:24:06,880 --> 00:24:09,600
But the standard
deviation is just the constant,

421
00:24:09,600 --> 00:24:13,760
you know,
or the value that's being multiplied here.

422
00:24:13,760 --> 00:24:16,360
Okay,

423
00:24:16,360 --> 00:24:28,760
does that make,
make sense?

424
00:24:28,760 --> 00:24:30,200
Okay,

425
00:24:30,200 --> 00:24:37,520
so let's look at actually going
back to the stochastic differential equation.

426
00:24:37,520 --> 00:24:42,320
There's different,
different flavors of the equation plotted here.

427
00:24:42,320 --> 00:24:45,960
This line
in the middle,

428
00:24:45,960 --> 00:24:47,320
this dashed line
in the middle,

429
00:24:47,320 --> 00:24:51,240
is just basically a constant.

430
00:24:51,240 --> 00:24:54,800
It's just saying that,
just for reference,

431
00:24:54,800 --> 00:24:56,920
it's just saying that nothing changes,

432
00:24:56,920 --> 00:25:00,000
it's actually not.

433
00:25:00,000 --> 00:25:01,840
These are,

434
00:25:01,840 --> 00:25:08,600
these are kind of the dashed lines are these non,
non stochastic equations just for reference.

435
00:25:08,600 --> 00:25:13,000
But if I have no deterministic part

436
00:25:13,000 --> 00:25:16,360
and I just have
the Wiener process,

437
00:25:16,360 --> 00:25:17,360
then just like before,

438
00:25:17,360 --> 00:25:21,320
it's just going
to kind of wander around starting from the,

439
00:25:21,320 --> 00:25:22,840
the zero mean,
right?

440
00:25:22,840 --> 00:25:29,320
That's the,
the equation at the, at the top.

441
00:25:29,320 --> 00:25:34,760
This one is,
this is a simple differential equation,

442
00:25:34,760 --> 00:25:36,160
this dashed line here,

443
00:25:36,160 --> 00:25:40,240
dx equals 2 dt,
that the,

444
00:25:40,240 --> 00:25:42,760
the coefficient is,

445
00:25:42,760 --> 00:25:44,440
is just a,

446
00:25:44,440 --> 00:25:46,080
a constant,
right?

447
00:25:46,080 --> 00:25:53,240
The,
the drift coefficient

448
00:25:53,240 --> 00:25:54,120
is just a constant.

449
00:25:54,120 --> 00:26:00,520
So,

450
00:26:00,520 --> 00:26:01,640
and then here,

451
00:26:01,640 --> 00:26:03,600
you see that,

452
00:26:03,600 --> 00:26:04,440
so you have this,

453
00:26:04,440 --> 00:26:06,840
it's just kind of growing,

454
00:26:06,840 --> 00:26:07,960
you know,

455
00:26:07,960 --> 00:26:10,000
linearly with,
with time,

456
00:26:10,000 --> 00:26:11,000
and then you're,

457
00:26:11,000 --> 00:26:14,480
you're adding the,
the Wiener process on,

458
00:26:14,480 --> 00:26:15,160
on top of it.

459
00:26:15,160 --> 00:26:18,200
And then the,
the line down here,

460
00:26:18,200 --> 00:26:20,120
now it's getting,

461
00:26:20,120 --> 00:26:21,200
you know,
a little bit more,

462
00:26:21,200 --> 00:26:23,480
you have the,
the drift coefficient

463
00:26:23,480 --> 00:26:28,760
is a simple function
of the random variable itself,

464
00:26:28,760 --> 00:26:35,840
and you have something,
some non unitary drift coefficient

465
00:26:35,840 --> 00:26:38,320
as well for the,

466
00:26:38,320 --> 00:26:41,160
the purple,
purple line here.

467
00:26:41,160 --> 00:26:42,680
And so,

468
00:26:42,680 --> 00:26:48,920
you can see that the standard deviation because we have a bigger constant,
multiplying the, the Wiener process,

469
00:26:48,920 --> 00:26:51,480
it's kind
of wandering around quite a bit,

470
00:26:51,480 --> 00:26:54,400
quite a bit more.

471
00:26:54,400 --> 00:26:58,680
Okay,
all right,

472
00:26:58,680 --> 00:26:59,160
so we,

473
00:26:59,160 --> 00:27:02,440
we want to reverse this,
this process,

474
00:27:02,440 --> 00:27:08,800
and so we had the,
the stochastic differential equation,

475
00:27:08,800 --> 00:27:12,320
and so here's where I'm going to start skipping a bunch
of math,

476
00:27:12,320 --> 00:27:13,040
but you know,

477
00:27:13,040 --> 00:27:14,720
can encourage you to,

478
00:27:14,720 --> 00:27:16,480
to do it,
or we can talk offline,

479
00:27:16,480 --> 00:27:19,360
is that we can just define this new

480
00:27:19,360 --> 00:27:22,320
variable
x hat,

481
00:27:22,320 --> 00:27:25,160
which is just instead of starting
from time zero

482
00:27:25,160 --> 00:27:28,200
and going to like time capital T,

483
00:27:28,200 --> 00:27:29,080
it's x hat,

484
00:27:29,080 --> 00:27:33,000
we just define it to be capital T minus T,
right?

485
00:27:33,000 --> 00:27:34,640
So if you have,

486
00:27:34,640 --> 00:27:35,840
basically when we're,

487
00:27:35,840 --> 00:27:39,840
we're going to be talking
a lot about time here,

488
00:27:39,840 --> 00:27:46,440
so probably can point to this that the normal diffusion process like I was showing

489
00:27:46,440 --> 00:27:48,000
is going
from zero to time

490
00:27:48,000 --> 00:27:48,800
T,

491
00:27:48,800 --> 00:27:57,200
and now x hat,
x hat is going,

492
00:27:57,200 --> 00:28:00,520
going back that way.

493
00:28:00,520 --> 00:28:04,200
So with some manipulations
and some substitutions,

494
00:28:04,200 --> 00:28:06,040
you can write what looks like,

495
00:28:06,040 --> 00:28:07,920
actually there,

496
00:28:07,920 --> 00:28:11,000
there's one thing that's also a little bit
different here,

497
00:28:11,000 --> 00:28:14,400
is that the diffusion coefficient is only dependent
on time,

498
00:28:14,400 --> 00:28:19,600
it's not dependent
on the random variable value itself,

499
00:28:19,600 --> 00:28:22,520
but with that assumption,

500
00:28:22,520 --> 00:28:24,080
you can write,

501
00:28:24,080 --> 00:28:27,120
you can rewrite the equation and then basically get it in a form,

502
00:28:27,120 --> 00:28:29,760
you know,

503
00:28:29,760 --> 00:28:35,800
substituting these variables<eol>, it looks very much like just another stochastic differential equation.

504
00:28:35,800 --> 00:28:38,880
Okay.

505
00:28:38,880 --> 00:28:40,440
And this,

506
00:28:40,440 --> 00:28:43,760
this term here has a special name,
the gradient of log

507
00:28:43,760 --> 00:28:45,280
of the probability distribution of the

508
00:28:45,280 --> 00:28:47,160
random variable,

509
00:28:47,160 --> 00:28:48,160
it's called

510
00:28:48,160 --> 00:28:50,160
the,
the score function,

511
00:28:50,160 --> 00:28:53,880
whereas the probability
of the random variable

512
00:28:53,880 --> 00:28:55,440
is just the,

513
00:28:55,440 --> 00:28:56,680
the marginal probability.

514
00:28:56,680 --> 00:29:00,520
Okay.

515
00:29:00,520 --> 00:29:10,160
So it turns out that if you have this,
this kind of stochastic differential equation,

516
00:29:10,160 --> 00:29:15,200
that if you carefully pick your,
your drift coefficient

517
00:29:15,200 --> 00:29:17,840
, your diffusion coefficient,

518
00:29:17,840 --> 00:29:19,280
that you can start with,

519
00:29:19,280 --> 00:29:21,960
you know,
any kind of distribution over here.

520
00:29:21,960 --> 00:29:26,760
And basically,

521
00:29:26,760 --> 00:29:38,480
you can guarantee that if you take enough steps that you will end up at some point with a,
just a pure Gaussian distribution.

522
00:29:38,480 --> 00:29:38,920
So you're,

523
00:29:38,920 --> 00:29:40,600
this is,

524
00:29:40,600 --> 00:29:43,240
so it's an equation that,

525
00:29:43,240 --> 00:29:46,280
you know,

526
00:29:46,280 --> 00:29:54,400
essentially diffuses the,
your complicated distribution to a simple Gaussian distribution.

527
00:29:54,400 --> 00:30:01,200
And,
and this is the form of the equations that will be used in the diffusion modeling.

528
00:30:01,200 --> 00:30:02,360
I warned you guys,

529
00:30:02,360 --> 00:30:09,520
it can be a lot of,
a lot of math,

530
00:30:09,520 --> 00:30:15,040
right?

531
00:30:15,040 --> 00:30:15,280
Okay.

532
00:30:15,280 --> 00:30:20,440
So let's develop
a little bit more intuition.

533
00:30:20,440 --> 00:30:22,280
So we had this,

534
00:30:22,280 --> 00:30:23,440
this form like I,

535
00:30:23,440 --> 00:30:27,280
I showed you here and that,

536
00:30:27,280 --> 00:30:28,200
so if you,

537
00:30:28,200 --> 00:30:30,760
you pick it,
the values of this form

538
00:30:30,760 --> 00:30:31,640
and

539
00:30:31,640 --> 00:30:31,960
p

540
00:30:31,960 --> 00:30:33,800
is between zero and one,

541
00:30:33,800 --> 00:30:34,120
you know,

542
00:30:34,120 --> 00:30:36,600
you'll have this,
this property.

543
00:30:36,600 --> 00:30:37,080
And you can take,

544
00:30:37,080 --> 00:30:37,960
you know,

545
00:30:37,960 --> 00:30:38,760
step by step,

546
00:30:38,760 --> 00:30:44,400
you can substitute
for every subsequent step.

547
00:30:44,400 --> 00:30:49,000
Like for example,
at the final step over here,

548
00:30:49,000 --> 00:30:54,360
of course,
the equation is simply just the previous step.

549
00:30:54,360 --> 00:30:56,600
And then you just keep going back another step

550
00:30:56,600 --> 00:30:58,240
and substitute back in there

551
00:30:58,240 --> 00:31:04,080
and then when you do all of that,
you end up with a equation like this,

552
00:31:04,080 --> 00:31:06,320
which is kind
of of the same form.

553
00:31:06,320 --> 00:31:11,160
You have the,
your first sample value over here,

554
00:31:11,160 --> 00:31:16,280
and then you just have these,
this kind of sum of like the,

555
00:31:16,280 --> 00:31:19,200
the square root of square root of one minus p

556
00:31:19,200 --> 00:31:21,560
raised to the ith power of the summation.

557
00:31:21,560 --> 00:31:33,000
But they're all just multiplying
one of these Gaussian, these normal distribution random variables.

558
00:31:33,000 --> 00:31:35,280
And so when you're,

559
00:31:35,280 --> 00:31:38,640
of course,

560
00:31:38,640 --> 00:31:42,920
when you're multiplying
something like a normally distributed random variable

561
00:31:42,920 --> 00:31:43,600
or something,

562
00:31:43,600 --> 00:31:49,080
all you're doing is you're just changing the,
the variance of that random variable.

563
00:31:49,080 --> 00:31:54,440
So you can view this as simply
just a sum of independent Gaussians,

564
00:31:54,440 --> 00:32:07,120
which you can then just add up
all the standard deviations to get just a single, single Gaussian.

565
00:32:07,120 --> 00:32:09,560
Okay,

566
00:32:09,560 --> 00:32:14,760
so if you do that for large enough step sizes,

567
00:32:14,760 --> 00:32:20,480
then the,
the value here as T goes in Finnish, as T goes in Finnish,

568
00:32:20,480 --> 00:32:23,080
eventually going to go to zero.

569
00:32:23,080 --> 00:32:27,840
And this is just a geometric
series here.

570
00:32:27,840 --> 00:32:28,480
If you're looking at

571
00:32:28,480 --> 00:32:29,520
the,
the variance,

572
00:32:29,520 --> 00:32:33,240
so you,
you square the terms inside here

573
00:32:33,240 --> 00:32:41,720
as T goes to infinity, that this just collapses into this closed form representation from the geometric series.

574
00:32:41,720 --> 00:32:43,320
And as T goes
in Finnish,

575
00:32:43,320 --> 00:32:45,080
this just becomes one.

576
00:32:45,080 --> 00:32:46,040
And so this,

577
00:32:46,040 --> 00:32:48,120
this tells you that,

578
00:32:48,120 --> 00:32:51,600
again,
this diffusion process works analytically.

579
00:32:51,600 --> 00:32:53,400
You take enough steps,

580
00:32:53,400 --> 00:33:00,880
you're eventually going to get to just a unit
standard Gaussian.

581
00:33:00,880 --> 00:33:02,120
Okay,
and that,

582
00:33:02,120 --> 00:33:04,040
and that's what we're doing,
but with for images.

583
00:33:04,040 --> 00:33:05,120
Okay,

584
00:33:05,120 --> 00:33:12,080
you start here with a picture,
actually it already looks a little noisy picture of a cat.

585
00:33:12,080 --> 00:33:13,320
And then you're just adding,

586
00:33:13,320 --> 00:33:15,440
adding noise to the point where,

587
00:33:15,440 --> 00:33:16,400
you know,

588
00:33:16,400 --> 00:33:21,600
at some point you basically just have
a Gaussian random noise distributed image.

589
00:33:21,600 --> 00:33:25,560
And for every step,

590
00:33:25,560 --> 00:33:27,320
it's just that equation that I,

591
00:33:27,320 --> 00:33:27,800
that I showed you.

592
00:33:27,800 --> 00:33:30,200
So actually the forward pass,

593
00:33:30,200 --> 00:33:31,480
you don't have to learn anything.

594
00:33:31,480 --> 00:33:33,600
You can just use this,

595
00:33:33,600 --> 00:33:35,200
this process is that you're,

596
00:33:35,200 --> 00:33:38,840
you're adding noise
in this kind of structured,

597
00:33:38,840 --> 00:33:41,360
structured way,

598
00:33:41,360 --> 00:33:42,560
step by step.

599
00:33:42,560 --> 00:33:49,600
Okay,

600
00:33:49,600 --> 00:33:51,720
so the question is,

601
00:33:51,720 --> 00:33:53,880
so why,

602
00:33:53,880 --> 00:33:58,840
why use this seemingly complicated process?

603
00:33:58,840 --> 00:34:02,520
So it turns out that,

604
00:34:02,520 --> 00:34:08,880
you know,
gives us this kind of structured way of going step by step to go from any complex distribution

605
00:34:08,880 --> 00:34:11,600
to a standard normal distribution.

606
00:34:11,600 --> 00:34:15,960
And it does it in a way,

607
00:34:15,960 --> 00:34:22,720
and hopefully I'll show you enough to convince you that it does it in a way that you can learn
the reverse process.

608
00:34:22,720 --> 00:34:24,480
And generally,

609
00:34:24,480 --> 00:34:30,760
it's really easy to go from a original image

610
00:34:30,760 --> 00:34:38,560
to just a pure noise image,
right?

611
00:34:38,560 --> 00:34:41,360
You can just go through that process,

612
00:34:41,360 --> 00:34:43,120
but it is,

613
00:34:43,120 --> 00:34:43,960
you know,

614
00:34:43,960 --> 00:34:52,080
it's hard to go,
go the other way.

615
00:34:52,080 --> 00:34:54,120
But,

616
00:34:54,120 --> 00:34:56,760
you know,

617
00:34:56,760 --> 00:34:58,440
if you think about it,

618
00:34:58,440 --> 00:35:00,720
you do get some,
some clues.

619
00:35:00,720 --> 00:35:03,600
Like maybe this first step is difficult when you just have pure noise,

620
00:35:03,600 --> 00:35:04,960
but,

621
00:35:04,960 --> 00:35:05,040
you know,

622
00:35:05,040 --> 00:35:09,280
maybe you're getting something
that looks like a image,

623
00:35:09,280 --> 00:35:13,600
but those clues
kind of influence what happens,

624
00:35:13,600 --> 00:35:14,920
you know,

625
00:35:14,920 --> 00:35:18,320
now it's maybe just a little bit easier because,

626
00:35:18,320 --> 00:35:18,600
you know,

627
00:35:18,600 --> 00:35:21,600
you're starting
to get to,

628
00:35:21,600 --> 00:35:25,960
you know,
some sample in your space,

629
00:35:25,960 --> 00:35:27,000
and then it,

630
00:35:27,000 --> 00:35:28,240
you know,

631
00:35:28,240 --> 00:35:31,520
generally can get easier as you progress.

632
00:35:31,520 --> 00:35:35,200
And in fact,

633
00:35:35,200 --> 00:35:37,320
that's kind of key to this,

634
00:35:37,320 --> 00:35:41,880
so you can write it in a closed form like that,
the forward pass,

635
00:35:41,880 --> 00:35:43,160
which is not trained,

636
00:35:43,160 --> 00:35:44,840
you just apply
that equation,

637
00:35:44,840 --> 00:35:45,760
you know,

638
00:35:45,760 --> 00:35:48,200
you can just take the composition
of all those functions,

639
00:35:48,200 --> 00:35:52,360
and you could write a big function,

640
00:35:52,360 --> 00:35:57,640
you know,
that tries to go from random noise to your,

641
00:35:57,640 --> 00:35:58,360
you know,

642
00:35:58,360 --> 00:35:59,640
final image,

643
00:35:59,640 --> 00:36:01,400
but it's a really hard,

644
00:36:01,400 --> 00:36:03,000
you know,

645
00:36:03,000 --> 00:36:04,440
probably impossible thing to do.

646
00:36:04,440 --> 00:36:07,640
First of all,
it can be very large function,

647
00:36:07,640 --> 00:36:14,120
but it's also probably doesn't behave
well from a kind of a gradient perspective,

648
00:36:14,120 --> 00:36:19,920
you kind of have like one shot to try to learn this model,

649
00:36:19,920 --> 00:36:21,840
whereas when you do it in this

650
00:36:21,840 --> 00:36:27,680
step by step,
each of these mappings here,

651
00:36:27,680 --> 00:36:33,720
what usually happens is this is learning kind of a course step first,

652
00:36:33,720 --> 00:36:36,200
and then as the image gets better,

653
00:36:36,200 --> 00:36:40,520
it's learning
kind of finer and finer updates to get to the final image,

654
00:36:40,520 --> 00:36:44,320
that seems to be helping,

655
00:36:44,320 --> 00:36:49,320
and it also turns out
that the nature of this function can be the same,

656
00:36:49,320 --> 00:36:51,240
it's just a,

657
00:36:51,240 --> 00:36:52,200
actually I'll show you,

658
00:36:52,200 --> 00:36:56,640
it can be just like a UNET or a transformer model,

659
00:36:56,640 --> 00:37:01,000
and so you're just adapting,

660
00:37:01,000 --> 00:37:04,040
there's some parameterization,

661
00:37:04,040 --> 00:37:05,440
you know,

662
00:37:05,440 --> 00:37:08,960
like just the time step that's changing,

663
00:37:08,960 --> 00:37:11,480
and so you can actually reuse weights,

664
00:37:11,480 --> 00:37:13,320
you know,
learn a function

665
00:37:13,320 --> 00:37:13,760
G

666
00:37:13,760 --> 00:37:17,520
that takes as the image as its input,

667
00:37:17,520 --> 00:37:21,440
the noisy image,
and the time step,

668
00:37:21,440 --> 00:37:23,240
and it's that same model

669
00:37:23,240 --> 00:37:25,640
with just different inputs
and different time steps,

670
00:37:25,640 --> 00:37:29,720
and so it turns out
to be much more efficient

671
00:37:29,720 --> 00:37:34,040
just in terms of the number of parameters and the size of the model.

672
00:37:34,040 --> 00:37:37,320
So,

673
00:37:37,320 --> 00:37:39,840
and that's basically what it's saying here.

674
00:37:39,840 --> 00:37:43,920
So,

675
00:37:43,920 --> 00:37:47,440
and you know,
for these multi - step process

676
00:37:47,440 --> 00:37:51,520
just the gradient descent is better behaved.

677
00:37:51,520 --> 00:37:59,160
Okay.

678
00:37:59,160 --> 00:38:05,960
Yeah,

679
00:38:05,960 --> 00:38:10,000
this is the point I just made before,

680
00:38:10,000 --> 00:38:12,560
is that we can have the exact same,

681
00:38:12,560 --> 00:38:17,320
so now these aren't different transforms,
these are exact same transforms,

682
00:38:17,320 --> 00:38:18,880
and they're just,

683
00:38:18,880 --> 00:38:21,240
the arguments to them are just the image that's going in

684
00:38:21,240 --> 00:38:22,840
and which step that we're on,

685
00:38:22,840 --> 00:38:27,720
so we can reuse the process.

686
00:38:27,720 --> 00:38:33,400
So,
in a lot of ways,

687
00:38:33,400 --> 00:38:38,920
it's similar to variation<eol>al auto encoders with some key differences,

688
00:38:38,920 --> 00:38:41,120
so it is,

689
00:38:41,120 --> 00:38:44,240
it's going from the encode<eol>r or the diffusion,

690
00:38:44,240 --> 00:38:48,840
forward diffusion,
is going from a complex distribution

691
00:38:48,840 --> 00:38:50,080
to a simple,

692
00:38:50,080 --> 00:38:54,920
so like the encoder in the VAE,

693
00:38:54,920 --> 00:38:56,920
and it's learning

694
00:38:56,920 --> 00:39:06,680
decode<eol>r to go in the other direction to produce a sample that looks like something from your sample set,

695
00:39:06,680 --> 00:39:08,120
but as I mentioned that this,

696
00:39:08,120 --> 00:39:12,160
unlike VAE,
this is a multi - step process,

697
00:39:12,160 --> 00:39:13,600
the encoder is fixed,

698
00:39:13,600 --> 00:39:18,960
so we're not actually learning the encoder like in VAE,

699
00:39:18,960 --> 00:39:22,800
and we're using this diffusion process to train.

700
00:39:22,800 --> 00:39:30,800
The other big thing is that in VAE,
remember we were shrinking the latent space was a smaller dimension,

701
00:39:30,800 --> 00:39:34,960
but it's key here that the model
at each step

702
00:39:34,960 --> 00:39:39,400
has exact same size input as it has output,

703
00:39:39,400 --> 00:39:43,840
okay?

704
00:39:43,840 --> 00:39:44,320
All right,

705
00:39:44,320 --> 00:39:48,360
so I'm just gonna get a little bit deeper,

706
00:39:48,360 --> 00:39:49,640
I'm not gonna go through all the math.

707
00:39:49,640 --> 00:39:52,960
Anyone see
the problem with the,

708
00:39:52,960 --> 00:39:53,280
what is it,

709
00:39:53,280 --> 00:39:59,240
what do you see?

710
00:39:59,240 --> 00:39:59,280
Yeah,

711
00:39:59,280 --> 00:40:00,440
so it's still,

712
00:40:00,440 --> 00:40:02,520
again,
doing a lot better with words,

713
00:40:02,520 --> 00:40:04,800
but not perfect.

714
00:40:04,800 --> 00:40:07,200
Okay,

715
00:40:07,200 --> 00:40:10,080
but again,

716
00:40:10,080 --> 00:40:13,400
I'm not gonna go through all of the math here,

717
00:40:13,400 --> 00:40:17,480
but,
all right,

718
00:40:17,480 --> 00:40:18,640
so let's,

719
00:40:18,640 --> 00:40:24,720
so we're gonna assume that we're gonna operate
in T discrete steps,

720
00:40:24,720 --> 00:40:27,880
and we're gonna assume that these are Markov processes,

721
00:40:27,880 --> 00:40:40,160
and so they only depend
on the step before in the, in either direction.

722
00:40:40,160 --> 00:40:49,720
And so we can define the so - called transition probability that basically says,

723
00:40:49,720 --> 00:40:54,040
okay,
at a current time stamp,

724
00:40:54,040 --> 00:40:56,120
current sample,

725
00:40:56,120 --> 00:40:57,440
there's a distribution,

726
00:40:57,440 --> 00:41:00,520
this conditional distribution is saying that given,

727
00:41:00,520 --> 00:41:06,000
if I take
a new sample given the previous sample,

728
00:41:06,000 --> 00:41:11,200
that it's going
to be a normal distribution,

729
00:41:11,200 --> 00:41:15,400
and this is reminiscent
of that equation that I showed you,

730
00:41:15,400 --> 00:41:17,560
right?

731
00:41:17,560 --> 00:41:20,600
Because it's just going to be,

732
00:41:20,600 --> 00:41:24,400
the mean is going to be centered
around your last sample

733
00:41:24,400 --> 00:41:33,480
with that weighting that I showed you in that previous equation, and the variance,

734
00:41:33,480 --> 00:41:36,320
we're just multiplying
that,

735
00:41:36,320 --> 00:41:38,920
the previous value by some value

736
00:41:38,920 --> 00:41:40,200
beta,

737
00:41:40,200 --> 00:41:43,680
and so that's gonna influence
the variance or standard deviation.

738
00:41:43,680 --> 00:41:50,320
And this gives us some,
a way to do a trade - off

739
00:41:50,320 --> 00:41:58,920
between basically how much information to keep from the previous sample.

740
00:41:58,920 --> 00:41:59,880
Yeah,

741
00:41:59,880 --> 00:42:03,960
and so we can,
for this next sample,

742
00:42:03,960 --> 00:42:06,320
we can say,

743
00:42:06,320 --> 00:42:08,440
because this is the trick,

744
00:42:08,440 --> 00:42:09,520
we use,

745
00:42:09,520 --> 00:42:14,720
I guess a number
of times now with these Gaussian random variables,

746
00:42:14,720 --> 00:42:17,320
is that if you take
the previous

747
00:42:17,320 --> 00:42:19,160
random variable at t minus one,

748
00:42:19,160 --> 00:42:22,680
you multiply it by something,

749
00:42:22,680 --> 00:42:27,600
or actually,
this is a deterministic value.

750
00:42:27,600 --> 00:42:33,320
If you take the,
some random process,

751
00:42:33,320 --> 00:42:34,560
and you multiply it by something,

752
00:42:34,560 --> 00:42:38,920
you're just changing the standard
deviation and shifting it.

753
00:42:38,920 --> 00:42:43,600
So this is equivalent
to this up here,

754
00:42:43,600 --> 00:42:46,000
right?

755
00:42:46,000 --> 00:42:47,240
We're just shifting it

756
00:42:47,240 --> 00:42:48,120
and changing the

757
00:42:48,120 --> 00:42:49,320
standard
deviation.

758
00:42:49,320 --> 00:42:54,720
Okay,

759
00:42:54,720 --> 00:43:03,720
so we can go all the way
from step zero to step T

760
00:43:03,720 --> 00:43:06,160
in kind of this closed form,

761
00:43:06,160 --> 00:43:13,800
but it just becomes
the product of all of those equations.

762
00:43:13,800 --> 00:43:16,840
And so you have essentially those,

763
00:43:16,840 --> 00:43:20,000
the one minus betas that were here,

764
00:43:20,000 --> 00:43:22,840
this is just previous step.

765
00:43:22,840 --> 00:43:27,640
We can just multiply all those out,
right?

766
00:43:27,640 --> 00:43:34,320
And then you have the product of those terms,
right?

767
00:43:34,320 --> 00:43:40,600
So if you want to go figure out the probability
over all the steps,

768
00:43:40,600 --> 00:43:45,920
you just multiply the each step,

769
00:43:45,920 --> 00:43:53,360
that going back,
right?

770
00:43:53,360 --> 00:43:59,480
So it turns out
that with the choices of the drift

771
00:43:59,480 --> 00:44:02,200
and the diffusion coefficients,

772
00:44:02,200 --> 00:44:10,080
that you can write the transition probability
the probability of the previous sample.

773
00:44:10,080 --> 00:44:11,840
So now we're going back the other way.

774
00:44:11,840 --> 00:44:13,680
You can write
it

775
00:44:13,680 --> 00:44:15,600
in a kind of very similar way.

776
00:44:15,600 --> 00:44:20,320
So now this is the kind of the important direction because we have to figure out,

777
00:44:20,320 --> 00:44:21,880
we have to learn this.

778
00:44:21,880 --> 00:44:25,840
We want to denoise,
go back this way.

779
00:44:25,840 --> 00:44:28,960
And so we can write in this form,

780
00:44:28,960 --> 00:44:34,040
but it's going to be based on some function that's going to determine the mean

781
00:44:34,040 --> 00:44:37,960
and some function that's going to determine
the covariance.

782
00:44:37,960 --> 00:44:39,360
And we don't know what those are yet,

783
00:44:39,360 --> 00:44:41,720
but let's assume that they're parameterized,

784
00:44:41,720 --> 00:44:43,560
but they're basically,

785
00:44:43,560 --> 00:44:48,200
we can use deep learning models
to do that.

786
00:44:48,200 --> 00:44:52,360
Okay,

787
00:44:52,360 --> 00:44:56,760
so you can do the same thing
now in the reverse direction.

788
00:44:56,760 --> 00:45:00,040
If you're trying
to do over the whole sequence,

789
00:45:00,040 --> 00:45:07,160
it's just a product of all of those conditionals,
right?

790
00:45:07,160 --> 00:45:12,400
Going back.

791
00:45:12,400 --> 00:45:13,680
And yeah,

792
00:45:13,680 --> 00:45:18,160
just the starting term here was not dependent
on time.

793
00:45:18,160 --> 00:45:23,600
It's just a regular Gaussian.

794
00:45:23,600 --> 00:45:29,680
Okay,
so with a little leap of faith here,

795
00:45:29,680 --> 00:45:34,200
we have the function
going forward.

796
00:45:34,200 --> 00:45:35,240
This forward process,

797
00:45:35,240 --> 00:45:36,840
which is,

798
00:45:36,840 --> 00:45:38,520
we don't have to learn it.

799
00:45:38,520 --> 00:45:39,840
It's just defined here.

800
00:45:39,840 --> 00:45:44,160
And now we have this reverse process.

801
00:45:44,160 --> 00:45:48,280
And at least we have a description
for the probability distribution,

802
00:45:48,280 --> 00:45:53,400
but it's based on some parameters here that we have to learn.

803
00:45:53,400 --> 00:45:58,040
So,

804
00:45:58,040 --> 00:46:01,080
yeah,

805
00:46:01,080 --> 00:46:01,440
so the question is,

806
00:46:01,440 --> 00:46:03,960
how do we learn those parameters?

807
00:46:03,960 --> 00:46:05,080
And we're going to,

808
00:46:05,080 --> 00:46:06,760
we wanna train a deep learning model,

809
00:46:06,760 --> 00:46:07,640
so how do we

810
00:46:07,640 --> 00:46:10,320
define
the loss function?

811
00:46:10,320 --> 00:46:14,120
So,

812
00:46:14,120 --> 00:46:16,400
remember,

813
00:46:16,400 --> 00:46:18,080
we had a,

814
00:46:18,080 --> 00:46:18,760
we defined
a,

815
00:46:18,760 --> 00:46:21,360
or you can think of a probability
distribution when you're training,

816
00:46:21,360 --> 00:46:23,600
you have these example,

817
00:46:23,600 --> 00:46:24,200
your dataset.

818
00:46:24,200 --> 00:46:32,960
So you have a probability
distribution of the original model.

819
00:46:32,960 --> 00:46:35,120
And then you're going all the way
to the noise.

820
00:46:35,120 --> 00:46:37,680
And then when you come back,

821
00:46:37,680 --> 00:46:46,720
we have this probability
distribution of our denoising process.

822
00:46:46,720 --> 00:46:51,400
And the goal is to make this look like this,
right?

823
00:46:51,400 --> 00:46:55,600
So we want the result of our denoising,

824
00:46:55,600 --> 00:46:57,080
the probability
distribution,

825
00:46:57,080 --> 00:46:59,840
we want it to look like the distribution of our

826
00:46:59,840 --> 00:47:02,200
dataset,
of our sample set,

827
00:47:02,200 --> 00:47:04,920
right?

828
00:47:04,920 --> 00:47:08,680
And so,

829
00:47:08,680 --> 00:47:10,480
how do we compare probability
distributions?

830
00:47:10,480 --> 00:47:14,520
What's the measure,

831
00:47:14,520 --> 00:47:16,160
yeah?

832
00:47:16,160 --> 00:47:18,200
KL divergence.

833
00:47:18,200 --> 00:47:20,240
KL divergence,

834
00:47:20,240 --> 00:47:21,000
yeah,

835
00:47:21,000 --> 00:47:22,800
yeah.

836
00:47:22,800 --> 00:47:25,080
And so,

837
00:47:25,080 --> 00:47:26,920
similar to like in the VAE,

838
00:47:26,920 --> 00:47:32,720
we're going
to build a loss function that is going to try to find the models

839
00:47:32,720 --> 00:47:36,880
the parameterized models for the mean

840
00:47:36,880 --> 00:47:40,160
and the variance.

841
00:47:40,160 --> 00:47:47,160
So that the divergence
from the actual distribution to the learned denoised distribution is minimized.

842
00:47:47,160 --> 00:47:52,120
And this is where I'm going to wave my,
wave my hands.

843
00:47:52,120 --> 00:47:54,840
I'm going to skip a lot more math,

844
00:47:54,840 --> 00:47:57,720
you can thank me.

845
00:47:57,720 --> 00:47:58,800
But,

846
00:47:58,800 --> 00:47:59,440
you know,

847
00:47:59,440 --> 00:48:00,360
if you go through,

848
00:48:00,360 --> 00:48:01,240
there's a bunch
of tricks.

849
00:48:01,240 --> 00:48:01,520
And again,

850
00:48:01,520 --> 00:48:04,240
suggest you try this

851
00:48:04,240 --> 00:48:04,840
if you're interested,

852
00:48:04,840 --> 00:48:09,920
but I just captured
some of the tricks here.

853
00:48:09,920 --> 00:48:15,000
Expanding the probability
sub theta,

854
00:48:15,000 --> 00:48:18,040
use Jensen<eol>'s inequality.

855
00:48:18,040 --> 00:48:21,920
And so the equation
for that divergence,

856
00:48:21,920 --> 00:48:26,400
you can use Jensen<eol>'s inequality to find a upper bound.

857
00:48:26,400 --> 00:48:28,240
That's simpler.

858
00:48:28,240 --> 00:48:33,840
And so if you minimize the upper bound,
simpler equation,

859
00:48:33,840 --> 00:48:35,880
you're minimizing
the actual equation.

860
00:48:35,880 --> 00:48:39,360
So the book also talks
about this as well.

861
00:48:39,360 --> 00:48:41,520
There's some manipulations with

862
00:48:41,520 --> 00:48:43,280
Bayes theorem.

863
00:48:43,280 --> 00:48:44,960
There,

864
00:48:44,960 --> 00:48:47,600
you can take advantage
of the properties that the

865
00:48:47,600 --> 00:48:48,400
KL

866
00:48:48,400 --> 00:48:51,800
divergence, that both of these are Gaussian distributions.

867
00:48:51,800 --> 00:48:54,080
And so you can,

868
00:48:54,080 --> 00:48:55,920
there's some properties of

869
00:48:55,920 --> 00:48:57,120
KL

870
00:48:57,120 --> 00:49:00,000
divergence measures
of two Gaussians that you,

871
00:49:00,000 --> 00:49:01,560
you can use.

872
00:49:01,560 --> 00:49:03,880
And then there's actually another simplification suggested
by Ho et al

873
00:49:03,880 --> 00:49:08,080
in this paper of 2020.

874
00:49:08,080 --> 00:49:10,600
That simplified it even more.

875
00:49:10,600 --> 00:49:11,680
Just kind of,

876
00:49:11,680 --> 00:49:12,760
I guess,

877
00:49:12,760 --> 00:49:16,000
I don't know if he guessed,

878
00:49:16,000 --> 00:49:19,560
but it's not analytically derived,

879
00:49:19,560 --> 00:49:26,760
but it turns out that it actually works even a little bit
better than the analytical derivation.

880
00:49:26,760 --> 00:49:30,000
And so the forward process again,

881
00:49:30,000 --> 00:49:36,040
was what I showed you,
this reverse process where we have to learn these parameters.

882
00:49:36,040 --> 00:49:40,400
And then this kind
of the near final,

883
00:49:40,400 --> 00:49:41,800
it's like the simplified,

884
00:49:41,800 --> 00:49:44,480
it was the upper bound with Jensen<eol>'s inequality,

885
00:49:44,480 --> 00:49:47,680
and then this other step.

886
00:49:47,680 --> 00:49:49,400
But it's basically,

887
00:49:49,400 --> 00:49:52,640
what's kind of interesting here,

888
00:49:52,640 --> 00:49:54,600
is what is trying to do it every step,

889
00:49:54,600 --> 00:50:03,640
is trying to minimize the noise measures
of the sample that's coming in,

890
00:50:03,640 --> 00:50:10,120
and the noise that you're producing.

891
00:50:10,120 --> 00:50:13,600
Okay,

892
00:50:13,600 --> 00:50:21,320
so we can leave the math for the most part.

893
00:50:21,320 --> 00:50:22,000
Okay,

894
00:50:22,000 --> 00:50:24,520
so it's very involved,
how to get in the training process,

895
00:50:24,520 --> 00:50:26,480
but I'm gonna summarize
it at a high level.

896
00:50:26,480 --> 00:50:27,080
So again,

897
00:50:27,080 --> 00:50:29,400
maybe you got some intuition.

898
00:50:29,400 --> 00:50:31,400
And I did ask Xavier,

899
00:50:31,400 --> 00:50:36,160
I didn't find a good small example.

900
00:50:36,160 --> 00:50:38,800
I think he showed some of

901
00:50:38,800 --> 00:50:40,800
VAE and GAN example,
right?

902
00:50:40,800 --> 00:50:43,600
Anyone go to the discussion
section?

903
00:50:43,600 --> 00:50:44,680
Yeah,

904
00:50:44,680 --> 00:50:48,080
so I asked him to do a diffusion example for next week.

905
00:50:48,080 --> 00:50:50,240
We'll see if you can find a good,

906
00:50:50,240 --> 00:50:52,360
simple example.

907
00:50:52,360 --> 00:50:54,720
But the idea is basically this.

908
00:50:54,720 --> 00:50:58,520
And so this is the training process.

909
00:50:58,520 --> 00:51:02,840
So you start
with a sample image,

910
00:51:02,840 --> 00:51:05,840
and you have noise,

911
00:51:05,840 --> 00:51:09,120
and basically you generate a random step

912
00:51:09,120 --> 00:51:10,160
by adding the

913
00:51:10,160 --> 00:51:15,840
image,
the noise to the image.

914
00:51:15,840 --> 00:51:30,000
And then you try to take a guess at what the image would look like from this noisy image,
from through this parameterized model.

915
00:51:30,000 --> 00:51:32,120
And from that,

916
00:51:32,120 --> 00:51:37,560
you're estimating
the noise of the noisy image.

917
00:51:37,560 --> 00:51:43,360
And then for the gradient
descent step,

918
00:51:43,360 --> 00:51:50,000
you have the estimated noise and a measure
of the true noise.

919
00:51:50,000 --> 00:51:53,960
And you calculate
gradient descent,

920
00:51:53,960 --> 00:51:55,320
which I didn't cover.

921
00:51:55,320 --> 00:51:57,720
It's kind
of more involved,

922
00:51:57,720 --> 00:52:02,160
but you can update the model parameters when you do that.

923
00:52:02,160 --> 00:52:14,160
And there's some pseudo code there at the top,
kind of saying the similar thing.

924
00:52:14,160 --> 00:52:19,560
So when you sample it after you've trained,
the process is like this.

925
00:52:19,560 --> 00:52:21,800
So you start step one,

926
00:52:21,800 --> 00:52:25,440
so you just start
with pure random noise.

927
00:52:25,440 --> 00:52:27,640
You're estimating,

928
00:52:27,640 --> 00:52:32,720
so you're using this model that you've learned to estimate
the noise of the current state.

929
00:52:32,720 --> 00:52:41,600
You take a first best guess of some image that's not gonna look very good.

930
00:52:41,600 --> 00:52:51,360
And then you do a linear combination
between the current state

931
00:52:51,360 --> 00:52:55,960
and the estimated noise from the original sample

932
00:52:55,960 --> 00:52:58,240
to create a new sample.

933
00:52:58,240 --> 00:53:04,400
And basically you just,
you keep doing that through that transform.

934
00:53:04,400 --> 00:53:14,040
And then you'll progressively
get better.

935
00:53:14,040 --> 00:53:15,960
That's the pseudo code for it.

936
00:53:15,960 --> 00:53:17,880
But so the model you can use,

937
00:53:17,880 --> 00:53:20,440
just you can just use the good old

938
00:53:20,440 --> 00:53:28,680
UNET,
the old encoder decoder architecture with some kind of time embedding.

939
00:53:28,680 --> 00:53:30,200
UNET is nice

940
00:53:30,200 --> 00:53:36,440
because you have the exact same resolution
of your input to your output,

941
00:53:36,440 --> 00:53:39,240
right?

942
00:53:39,240 --> 00:53:43,120
That's one of the requirements.

943
00:53:43,120 --> 00:53:46,480
I think this is literally the size
of the model.

944
00:53:46,480 --> 00:53:48,840
The thing that's,

945
00:53:48,840 --> 00:53:51,800
not sure when it was added,

946
00:53:51,800 --> 00:53:55,080
but there is these residual blocks,
the normal residual blocks from UNET,

947
00:53:55,080 --> 00:53:55,680
right?

948
00:53:55,680 --> 00:53:59,920
So you,
these are convolutional layers,

949
00:53:59,920 --> 00:54:05,120
and then you have these residual connections
that get added in when you're doing the deconvolution side.

950
00:54:05,120 --> 00:54:10,600
But they also added these residual blocks
with self - attention,

951
00:54:10,600 --> 00:54:11,800
so kind of interesting.

952
00:54:11,800 --> 00:54:21,680
So taking a little bit
from the transformer architecture and putting a self - attention head.

953
00:54:21,680 --> 00:54:23,760
And I don't know,

954
00:54:23,760 --> 00:54:25,000
I have to check,

955
00:54:25,000 --> 00:54:25,960
or you guys can check,

956
00:54:25,960 --> 00:54:27,640
like how many,

957
00:54:27,640 --> 00:54:31,680
if it's multi - headed attention
or not.

958
00:54:31,680 --> 00:54:33,160
But that's,

959
00:54:33,160 --> 00:54:33,640
you know,

960
00:54:33,640 --> 00:54:38,360
the complicated part was,
or is deriving the loss function.

961
00:54:38,360 --> 00:54:39,120
You know,

962
00:54:39,120 --> 00:54:39,800
once you have the

963
00:54:39,800 --> 00:54:46,360
loss function,
the model architecture itself is not complicated.

964
00:54:46,360 --> 00:54:49,920
And yeah,

965
00:54:49,920 --> 00:54:55,160
so basically you train that model.

966
00:54:55,160 --> 00:54:57,000
It has the time step that's coming in,

967
00:54:57,000 --> 00:55:00,400
but you're just running that model at every step.

968
00:55:00,400 --> 00:55:04,880
This is actually the reverse process,

969
00:55:04,880 --> 00:55:09,520
even though it's going to the right.

970
00:55:09,520 --> 00:55:11,160
And there's,

971
00:55:11,160 --> 00:55:12,000
but you can imagine,

972
00:55:12,000 --> 00:55:15,520
there's just been
a ton of innovation and experimentation here.

973
00:55:15,520 --> 00:55:17,440
I'll show you a couple of examples,

974
00:55:17,440 --> 00:55:18,040
but they,

975
00:55:18,040 --> 00:55:20,080
you know,
trying lots of even transformer base.

976
00:55:20,080 --> 00:55:21,560
Yeah.

977
00:55:21,560 --> 00:55:24,000
Sorry,

978
00:55:24,000 --> 00:55:26,600
I can't see that the difference
between the heat of the rocks.

979
00:55:26,600 --> 00:55:33,720
Down here?

980
00:55:33,720 --> 00:55:34,560
Yeah,

981
00:55:34,560 --> 00:55:37,760
it's the exact same model.

982
00:55:37,760 --> 00:55:40,360
There's nothing changing.

983
00:55:40,360 --> 00:55:42,240
It's getting
the time index coming in.

984
00:55:42,240 --> 00:55:44,200
So it has the,

985
00:55:44,200 --> 00:55:46,880
of course,
different input.

986
00:55:46,880 --> 00:55:50,520
And then I think it's kind of showing it here.

987
00:55:50,520 --> 00:55:55,720
There's a time embedding that's incorporated
as well.

988
00:55:55,720 --> 00:56:00,880
And I'm not exactly sure
offhand how,

989
00:56:00,880 --> 00:56:06,000
but is that your question?

990
00:56:06,000 --> 00:56:09,640
What exactly does text come in?

991
00:56:09,640 --> 00:56:10,200
Yeah,

992
00:56:10,200 --> 00:56:13,440
so text is conditional generation.

993
00:56:13,440 --> 00:56:13,840
So the,

994
00:56:13,840 --> 00:56:14,680
yeah.

995
00:56:14,680 --> 00:56:16,680
So indeed,

996
00:56:16,680 --> 00:56:21,160
it didn't incorporate any kind of external additional prompting.

997
00:56:21,160 --> 00:56:22,760
And so there's,

998
00:56:22,760 --> 00:56:25,200
of course,
a lot of variants here,

999
00:56:25,200 --> 00:56:26,880
but I call out two of them.

1000
00:56:26,880 --> 00:56:30,280
Is there's classifier guidance like I showed on the,

1001
00:56:30,280 --> 00:56:33,760
was it the VAE or GAN lecture
now,

1002
00:56:33,760 --> 00:56:37,200
but where you're incorporating
class information

1003
00:56:37,200 --> 00:56:40,000
and you're influencing the reconstruction based on class,

1004
00:56:40,000 --> 00:56:40,880
and I'll show you a picture

1005
00:56:40,880 --> 00:56:44,480
example,
or guidance from text.

1006
00:56:44,480 --> 00:56:46,640
And basically what you're doing is you're incorporating,

1007
00:56:46,640 --> 00:56:48,040
you're using a language model,

1008
00:56:48,040 --> 00:56:53,080
like a transformer,
to create an embedding.

1009
00:56:53,080 --> 00:56:55,640
And then you're adding that,

1010
00:56:55,640 --> 00:56:57,360
you're injecting
that into the flow.

1011
00:56:57,360 --> 00:57:00,600
And I have a,

1012
00:57:00,600 --> 00:57:04,800
I think I have a picture here.

1013
00:57:04,800 --> 00:57:05,440
But,

1014
00:57:05,440 --> 00:57:08,800
and then there's other examples,

1015
00:57:08,800 --> 00:57:10,320
like I mentioned at the very beginning,

1016
00:57:10,320 --> 00:57:12,720
that you can also show it a sketch and text.

1017
00:57:12,720 --> 00:57:16,760
So there's variations
here.

1018
00:57:16,760 --> 00:57:17,680
But here's,

1019
00:57:17,680 --> 00:57:21,480
this is this paper by Dari Wal and Nickel,

1020
00:57:21,480 --> 00:57:24,080
that's doing,

1021
00:57:24,080 --> 00:57:24,720
again,

1022
00:57:24,720 --> 00:57:31,000
it's ImageNet,
and is just taking the ImageNet class as guidance here.

1023
00:57:31,000 --> 00:57:34,640
And so you can imagine that it didn't put the labels here.

1024
00:57:34,640 --> 00:57:36,240
This is an example from the book,

1025
00:57:36,240 --> 00:57:39,560
but you can kind of guess what the class labels are,

1026
00:57:39,560 --> 00:57:40,160
and it's doing,

1027
00:57:40,160 --> 00:57:46,080
you know,
high quality generation.

1028
00:57:46,080 --> 00:57:49,920
So,

1029
00:57:49,920 --> 00:57:53,120
but yeah,
so for text,

1030
00:57:53,120 --> 00:57:54,440
this is one example.

1031
00:57:54,440 --> 00:57:56,880
This is Saharia,

1032
00:57:56,880 --> 00:57:59,920
and I guess pretty recent,
2022,

1033
00:57:59,920 --> 00:58:02,320
but this is taking a language model,

1034
00:58:02,320 --> 00:58:04,000
but it's also doing this

1035
00:58:04,000 --> 00:58:06,680
hierarchical,
this kind of cascaded.

1036
00:58:06,680 --> 00:58:08,920
So it does low resolution,

1037
00:58:08,920 --> 00:58:18,720
and then that feeds into a slightly higher resolution,
and then that feeds into a slightly higher resolution as well.

1038
00:58:18,720 --> 00:58:22,440
But you see the embedding vectors are injected,

1039
00:58:22,440 --> 00:58:29,120
and I don't know off<eol>hand the exact architecture,

1040
00:58:29,120 --> 00:58:39,000
but you can imagine that it's being added
at some of the layers.

1041
00:58:39,000 --> 00:58:39,800
I mean,

1042
00:58:39,800 --> 00:58:40,960
for UNET,

1043
00:58:40,960 --> 00:58:50,480
it's probably
being remapped into two - dimensional kind of feature vector,

1044
00:58:50,480 --> 00:58:54,040
so that it can be added in,
or it could be,

1045
00:58:54,040 --> 00:58:58,040
you know,
weighted across channels or something.

1046
00:58:58,040 --> 00:59:03,360
You have to look at the paper to see exactly how.

1047
00:59:03,360 --> 00:59:04,080
But of course,

1048
00:59:04,080 --> 00:59:05,440
yeah,

1049
00:59:05,440 --> 00:59:08,000
so lots of examples now.

1050
00:59:08,000 --> 00:59:11,200
This was again from the Saharia paper,

1051
00:59:11,200 --> 00:59:12,640
but and I guess,

1052
00:59:12,640 --> 00:59:14,480
okay,

1053
00:59:14,480 --> 00:59:15,400
this is,

1054
00:59:15,400 --> 00:59:18,040
imagine this is the Google model.

1055
00:59:18,040 --> 00:59:20,960
And so,

1056
00:59:20,960 --> 00:59:27,160
yeah,

1057
00:59:27,160 --> 00:59:37,160
I'm not gonna go into it here,
but stable diffusion kind of really kicked off because it was more efficient

1058
00:59:37,160 --> 00:59:41,240
and slightly higher quality,

1059
00:59:41,240 --> 00:59:49,000
but it's using a encode<eol>r - decoder with attention kind of architecture,

1060
00:59:49,000 --> 00:59:51,560
and I guess it's not really showing it here.

1061
00:59:51,560 --> 00:59:54,840
I mean,
this is like their overall diagram.

1062
00:59:54,840 --> 00:59:59,480
Maybe it's kind of represented here,

1063
00:59:59,480 --> 01:00:05,760
but it's reducing the size
into kind of like a smaller embedding space,

1064
01:00:05,760 --> 01:00:15,120
denoising and then upscaling
to the higher resolution.

1065
01:00:15,120 --> 01:00:18,520
But it's also,

1066
01:00:18,520 --> 01:00:21,680
you know, able
to condition on images,

1067
01:00:21,680 --> 01:00:24,480
some other representation,
some kind of

1068
01:00:24,480 --> 01:00:25,920
semantic map or text,

1069
01:00:25,920 --> 01:00:31,040
so you could condition
it on a lot of different things

1070
01:00:31,040 --> 01:00:36,480
and it seems to work well.

1071
01:00:36,480 --> 01:00:40,680
So I thought I'd throw this picture in because I was trying to create it

1072
01:00:40,680 --> 01:00:42,240
and I wasn't successful

1073
01:00:42,240 --> 01:00:45,280
and I think the way it failed is kind of interesting.

1074
01:00:45,280 --> 01:00:47,640
So on Dali 3 now,

1075
01:00:47,640 --> 01:00:50,360
they have this new feature.

1076
01:00:50,360 --> 01:00:53,480
So my original prompt was this.

1077
01:00:53,480 --> 01:00:57,920
So I wanted to use it as the transition in the slide

1078
01:00:57,920 --> 01:01:02,560
where it's a Victorian butcher dressed,
cranking a meat grinder,

1079
01:01:02,560 --> 01:01:06,000
but math symbols
are going in

1080
01:01:06,000 --> 01:01:08,080
and nice pictures are falling out.

1081
01:01:08,080 --> 01:01:11,240
And so actually what,

1082
01:01:11,240 --> 01:01:13,400
this is not my first iteration,

1083
01:01:13,400 --> 01:01:15,680
but it was actually
ground meat look kind of disgusting,

1084
01:01:15,680 --> 01:01:18,560
so I didn't include that picture.

1085
01:01:18,560 --> 01:01:20,360
So the interesting thing about Dali 3

1086
01:01:20,360 --> 01:01:20,880
now

1087
01:01:20,880 --> 01:01:22,680
is that you can go into it

1088
01:01:22,680 --> 01:01:25,440
and you can actually select part of the image.

1089
01:01:25,440 --> 01:01:27,360
And so,

1090
01:01:27,360 --> 01:01:30,040
and this is where diffusion models also,

1091
01:01:30,040 --> 01:01:34,640
you know,
one of their strengths is in painting.

1092
01:01:34,640 --> 01:01:38,080
So I just selected all of the ground meat here

1093
01:01:38,080 --> 01:01:40,120
and then I tried it again.

1094
01:01:40,120 --> 01:01:41,040
And by the way,

1095
01:01:41,040 --> 01:01:44,200
remember in Dali 3,
behind the scenes,

1096
01:01:44,200 --> 01:01:46,080
it's creating a much more detailed.

1097
01:01:46,080 --> 01:01:47,640
So it's using an LLM,

1098
01:01:47,640 --> 01:01:50,360
actually using GPT - 4

1099
01:01:50,360 --> 01:01:54,760
to create a very detailed prompt that it doesn't even show you

1100
01:01:54,760 --> 01:01:59,560
unless you kind
of click on the info button.

1101
01:01:59,560 --> 01:02:05,200
So it's interesting how they've trained this more detailed prompt.

1102
01:02:05,200 --> 01:02:11,120
And even on the detailed prompt,

1103
01:02:11,120 --> 01:02:14,120
it is saying that I want math symbols
going in

1104
01:02:14,120 --> 01:02:16,360
and pictures coming out.

1105
01:02:16,360 --> 01:02:21,000
And I even masked this and told it to do it again.

1106
01:02:21,000 --> 01:02:22,040
But,

1107
01:02:22,040 --> 01:02:22,840
you know,

1108
01:02:22,840 --> 01:02:26,800
you can think that,
at least in the probability distribution,

1109
01:02:26,800 --> 01:02:31,800
apparently it was so far out
of the distribution of having like a meat grinder doing math.

1110
01:02:31,800 --> 01:02:33,840
I just couldn't get it.

1111
01:02:33,840 --> 01:02:35,760
I couldn't steer it,

1112
01:02:35,760 --> 01:02:38,120
you know,
out of this mode,

1113
01:02:38,120 --> 01:02:39,000
kind of realistic.

1114
01:02:39,000 --> 01:02:41,320
It did draw
a lot of symbols on the meat grinder itself,

1115
01:02:41,320 --> 01:02:43,040
funny enough.

1116
01:02:43,040 --> 01:02:44,400
You know,

1117
01:02:44,400 --> 01:02:45,240
I didn't ask it to,

1118
01:02:45,240 --> 01:02:48,800
but I think it's kind
of indicative of that,

1119
01:02:48,800 --> 01:02:52,840
you know,
you're playing with these distributions and,

1120
01:02:52,840 --> 01:02:53,800
you know,

1121
01:02:53,800 --> 01:02:55,400
I could not get it out of the,

1122
01:02:55,400 --> 01:02:58,400
you know,
the more central mode of,

1123
01:02:58,400 --> 01:03:02,720
you know,
a picture of a Victorian butcher with a meat grinder.

1124
01:03:02,720 --> 01:03:08,440
But you can imagine,
so in - painting

1125
01:03:08,440 --> 01:03:10,600
is kind of a easy conditioning process,

1126
01:03:10,600 --> 01:03:11,680
right?

1127
01:03:11,680 --> 01:03:14,680
So you just mask out this area.

1128
01:03:14,680 --> 01:03:17,080
You just provide
the rest of the image with a mask,

1129
01:03:17,080 --> 01:03:19,600
the masked area,

1130
01:03:19,600 --> 01:03:24,240
and then just do noise
and diffusion on that part,

1131
01:03:24,240 --> 01:03:26,920
you know,
conditioned on everything else.

1132
01:03:26,920 --> 01:03:28,320
So it's,

1133
01:03:28,320 --> 01:03:30,560
you know,
it has a lot of flexibility.

1134
01:03:30,560 --> 01:03:32,800
And of course,
they're using it for music

1135
01:03:32,800 --> 01:03:34,240
and everything else as well.

1136
01:03:34,240 --> 01:03:37,480
Okay,

1137
01:03:37,480 --> 01:03:39,760
so if you wanna,

1138
01:03:39,760 --> 01:03:41,480
this,

1139
01:03:41,480 --> 01:03:42,080
here's the link again.

1140
01:03:42,080 --> 01:03:44,840
Let me know if you don't have access
to the blog post.

1141
01:03:44,840 --> 01:03:50,440
I think it helps make the chapter a little bit
more readable too.

1142
01:03:50,440 --> 01:03:54,160
And then there's a CVPR 2023 last year.

1143
01:03:54,160 --> 01:03:58,800
There was a tutorial,
it's like a five - hour tutorial.

1144
01:03:58,800 --> 01:04:00,760
If you wanna go,

1145
01:04:00,760 --> 01:04:03,600
you know,
it starts from,

1146
01:04:03,600 --> 01:04:04,280
you know,

1147
01:04:04,280 --> 01:04:05,440
like where I started,

1148
01:04:05,440 --> 01:04:11,120
but it goes pretty quickly into the,
into more details.

1149
01:04:11,120 --> 01:04:13,800
There's another version,
the next version at

1150
01:04:13,800 --> 01:04:15,280
CVPR this year.

1151
01:04:15,280 --> 01:04:17,320
They're doing it again as well.

1152
01:04:17,320 --> 01:04:20,480
All right,

1153
01:04:20,480 --> 01:04:21,560
so,

1154
01:04:21,560 --> 01:04:22,000
okay,

1155
01:04:22,000 --> 01:04:23,680
so that's it for diffusion.

1156
01:04:23,680 --> 01:04:25,600
So next time it's,

1157
01:04:25,600 --> 01:04:34,840
I'm doing graph neural networks and then reinforcement
learning.

1158
01:04:34,840 --> 01:04:35,800
And again,

1159
01:04:35,800 --> 01:04:37,360
I'm gonna try to focus on like

1160
01:04:37,360 --> 01:04:42,960
RLHF because I know at least half the class is taking reinforcement
learning.

1161
01:04:42,960 --> 01:04:45,040
So,

1162
01:04:45,040 --> 01:04:47,720
and then please for the leaderboard people,
work with Xavier

1163
01:04:47,720 --> 01:04:50,280
and get that slide or two together.

1164
01:04:50,280 --> 01:04:50,920
All right,

1165
01:04:50,920 --> 01:04:56,240
thank you.

